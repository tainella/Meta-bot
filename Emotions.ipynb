{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Emotions.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2asSSJGztBv"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import warnings\n",
        "import math\n",
        "import tensorflow as tf\n",
        "warnings.simplefilter(\"ignore\")\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.metrics import mean_squared_error\n",
        "from sklearn.metrics import f1_score\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6NdpsBFz6QV",
        "outputId": "ecefbb5b-1905-46f0-a372-92e40bb14fd9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "wWudcFpz0Bfk",
        "outputId": "f7005cf8-231e-4c53-f217-db1a467f58cf"
      },
      "source": [
        "data = pd.read_csv(\"/content/gdrive/MyDrive/fer2013.csv\")\n",
        "data.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>pixels</th>\n",
              "      <th>Usage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   emotion                                             pixels     Usage\n",
              "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
              "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
              "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
              "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
              "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHIr1BSp2FSz",
        "outputId": "3d502fcc-d9ab-4633-bbb9-dbeb5bd38cc5"
      },
      "source": [
        "data_train = data[data['Usage']=='Training'].copy()\n",
        "data_val   = data[data['Usage']=='PublicTest'].copy()\n",
        "data_test  = data[data['Usage']=='PrivateTest'].copy()\n",
        "print(\"train shape: {}, \\nvalidation shape: {}, \\ntest shape: {}\".format(data_train.shape, data_val.shape, data_test.shape))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train shape: (28709, 3), \n",
            "validation shape: (3589, 3), \n",
            "test shape: (3589, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxk4g9hs2pWr"
      },
      "source": [
        "num_classes = 7 \n",
        "width, height = 48, 48\n",
        "num_epochs = 50\n",
        "batch_size = 64\n",
        "num_features = 64"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UT2Dd73m63rX",
        "outputId": "50b4871c-1d59-4dfc-cf7c-44cc12b9a369"
      },
      "source": [
        "data['pixels'].dtype"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('O')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ll6yDtYO2NQZ"
      },
      "source": [
        "n_samples = len(data)\n",
        "n_samples_train = 28709\n",
        "n_samples_test = 3589\n",
        "n_samples_validation = 3589\n",
        "\n",
        "y = data['emotion']\n",
        "X = np.zeros((n_samples, width, height, 1))\n",
        "for i in range(n_samples):\n",
        "    X[i] = np.array([int(pixel) for pixel in data['pixels'][i].split()]).reshape(48,48,1)\n",
        "\n",
        "#Training set   \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=10)"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAclnVJEpeSk"
      },
      "source": [
        "y_train = to_categorical(y_train)"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1ON70yG0Mom"
      },
      "source": [
        "resnet = tf.keras.applications.resnet50.ResNet50(include_top=True, weights=None, input_shape=(48,48,1), classes=7, pooling='average', classifier_activation='softmax')"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8T5_97qt-Ic-"
      },
      "source": [
        "resnet.compile(loss='categorical_crossentropy', \n",
        "              optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-7), \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDW-SaDM1T3E",
        "outputId": "67a4d99e-4317-4cc7-ecb2-e125068ee3ee"
      },
      "source": [
        "resnet.fit(X_train, y_train, epochs = 40)"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "1010/1010 [==============================] - 119s 111ms/step - loss: 1.8531 - accuracy: 0.3267\n",
            "Epoch 2/40\n",
            "1010/1010 [==============================] - 111s 110ms/step - loss: 1.5703 - accuracy: 0.4195\n",
            "Epoch 3/40\n",
            "1010/1010 [==============================] - 111s 110ms/step - loss: 1.5580 - accuracy: 0.4271\n",
            "Epoch 4/40\n",
            "1010/1010 [==============================] - 111s 110ms/step - loss: 1.7219 - accuracy: 0.3606\n",
            "Epoch 5/40\n",
            "1010/1010 [==============================] - 111s 110ms/step - loss: 1.5602 - accuracy: 0.4092\n",
            "Epoch 6/40\n",
            "1010/1010 [==============================] - 111s 110ms/step - loss: 1.3613 - accuracy: 0.4779\n",
            "Epoch 7/40\n",
            "1010/1010 [==============================] - 111s 110ms/step - loss: 1.3186 - accuracy: 0.5016\n",
            "Epoch 8/40\n",
            "1010/1010 [==============================] - 112s 110ms/step - loss: 1.2640 - accuracy: 0.5188\n",
            "Epoch 9/40\n",
            "1010/1010 [==============================] - 111s 110ms/step - loss: 1.1710 - accuracy: 0.5569\n",
            "Epoch 10/40\n",
            "1010/1010 [==============================] - 112s 111ms/step - loss: 1.0880 - accuracy: 0.5887\n",
            "Epoch 11/40\n",
            "1010/1010 [==============================] - 112s 111ms/step - loss: 1.0236 - accuracy: 0.6142\n",
            "Epoch 12/40\n",
            "1010/1010 [==============================] - 112s 111ms/step - loss: 1.0053 - accuracy: 0.6234\n",
            "Epoch 13/40\n",
            "1010/1010 [==============================] - 113s 111ms/step - loss: 0.8800 - accuracy: 0.6721\n",
            "Epoch 14/40\n",
            "1010/1010 [==============================] - 113s 111ms/step - loss: 0.7742 - accuracy: 0.7166\n",
            "Epoch 15/40\n",
            "1010/1010 [==============================] - 112s 111ms/step - loss: 0.6985 - accuracy: 0.7445\n",
            "Epoch 16/40\n",
            "1010/1010 [==============================] - 112s 111ms/step - loss: 0.5987 - accuracy: 0.7802\n",
            "Epoch 17/40\n",
            "1010/1010 [==============================] - 112s 111ms/step - loss: 0.4815 - accuracy: 0.8258\n",
            "Epoch 18/40\n",
            "1010/1010 [==============================] - 113s 111ms/step - loss: 0.3990 - accuracy: 0.8552\n",
            "Epoch 19/40\n",
            "1010/1010 [==============================] - 113s 112ms/step - loss: 0.3404 - accuracy: 0.8793\n",
            "Epoch 20/40\n",
            "1010/1010 [==============================] - 112s 111ms/step - loss: 0.2927 - accuracy: 0.8946\n",
            "Epoch 21/40\n",
            "1010/1010 [==============================] - 113s 112ms/step - loss: 0.2470 - accuracy: 0.9118\n",
            "Epoch 22/40\n",
            "1010/1010 [==============================] - 113s 112ms/step - loss: 0.2188 - accuracy: 0.9228\n",
            "Epoch 23/40\n",
            "1010/1010 [==============================] - 113s 112ms/step - loss: 0.1908 - accuracy: 0.9321\n",
            "Epoch 24/40\n",
            "1010/1010 [==============================] - 113s 111ms/step - loss: 0.1794 - accuracy: 0.9369\n",
            "Epoch 25/40\n",
            "1010/1010 [==============================] - 113s 111ms/step - loss: 0.1556 - accuracy: 0.9466\n",
            "Epoch 26/40\n",
            "1010/1010 [==============================] - 113s 112ms/step - loss: 0.1458 - accuracy: 0.9496\n",
            "Epoch 27/40\n",
            "1010/1010 [==============================] - 112s 111ms/step - loss: 0.1402 - accuracy: 0.9512\n",
            "Epoch 28/40\n",
            "1010/1010 [==============================] - 112s 111ms/step - loss: 0.1301 - accuracy: 0.9559\n",
            "Epoch 29/40\n",
            "1010/1010 [==============================] - 113s 111ms/step - loss: 0.1266 - accuracy: 0.9568\n",
            "Epoch 30/40\n",
            "1010/1010 [==============================] - 113s 112ms/step - loss: 0.1163 - accuracy: 0.9599\n",
            "Epoch 31/40\n",
            "1010/1010 [==============================] - 113s 111ms/step - loss: 0.1182 - accuracy: 0.9590\n",
            "Epoch 32/40\n",
            "1010/1010 [==============================] - 112s 111ms/step - loss: 0.1009 - accuracy: 0.9644\n",
            "Epoch 33/40\n",
            "1010/1010 [==============================] - 112s 111ms/step - loss: 0.1021 - accuracy: 0.9646\n",
            "Epoch 34/40\n",
            "1010/1010 [==============================] - 112s 111ms/step - loss: 0.0954 - accuracy: 0.9673\n",
            "Epoch 35/40\n",
            "1010/1010 [==============================] - 112s 111ms/step - loss: 0.0909 - accuracy: 0.9687\n",
            "Epoch 36/40\n",
            "1010/1010 [==============================] - 112s 111ms/step - loss: 0.0870 - accuracy: 0.9698\n",
            "Epoch 37/40\n",
            "1010/1010 [==============================] - 112s 111ms/step - loss: 0.1046 - accuracy: 0.9637\n",
            "Epoch 38/40\n",
            "1010/1010 [==============================] - 112s 111ms/step - loss: 0.0882 - accuracy: 0.9692\n",
            "Epoch 39/40\n",
            "1010/1010 [==============================] - 112s 111ms/step - loss: 0.0897 - accuracy: 0.9681\n",
            "Epoch 40/40\n",
            "1010/1010 [==============================] - 112s 111ms/step - loss: 0.0884 - accuracy: 0.9688\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc2c5254e10>"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4K6gK8gbZ1Ez",
        "outputId": "2993190b-24c3-4446-a9d1-ec01a2355d27"
      },
      "source": [
        "resnet.save('/content/gdrive/MyDrive/resnet_model')"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/gdrive/MyDrive/resnet_model/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfTzgDxF-Fgt"
      },
      "source": [
        "pred = resnet.predict(X_test)"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hphm_x2yZ0t8"
      },
      "source": [
        "predictions = []\n",
        "for p in pred:\n",
        "  predictions.append(np.argmax(p))"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9R7E3fOKRKe",
        "outputId": "fb3ffed9-c8c3-4ce5-d181-312a5f3fa407"
      },
      "source": [
        "f1_score(y_test, predictions, average='weighted')"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.59265143609979"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84oDQCgmPVAT"
      },
      "source": [
        "vggnet = tf.keras.applications.vgg19.VGG19(include_top=True, weights=None, input_shape=(48,48,1), classes=7, pooling='max', classifier_activation='softmax')"
      ],
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2B6pDacoKWnL"
      },
      "source": [
        "vggnet.compile(loss='categorical_crossentropy', \n",
        "              optimizer=SGD(lr=0.01), \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljzFiRiFbHlO",
        "outputId": "c3cde62c-0a66-4917-b594-e84b2c827955"
      },
      "source": [
        "vggnet.fit(X_train, y_train, epochs = 40)"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "1010/1010 [==============================] - 111s 109ms/step - loss: 1.7426 - accuracy: 0.2985\n",
            "Epoch 2/40\n",
            "1010/1010 [==============================] - 110s 109ms/step - loss: 1.5854 - accuracy: 0.3844\n",
            "Epoch 3/40\n",
            "1010/1010 [==============================] - 110s 109ms/step - loss: 1.4760 - accuracy: 0.4315\n",
            "Epoch 4/40\n",
            "1010/1010 [==============================] - 110s 109ms/step - loss: 1.3975 - accuracy: 0.4634\n",
            "Epoch 5/40\n",
            "1010/1010 [==============================] - 110s 109ms/step - loss: 1.3122 - accuracy: 0.4966\n",
            "Epoch 6/40\n",
            "1010/1010 [==============================] - 110s 109ms/step - loss: 1.2323 - accuracy: 0.5312\n",
            "Epoch 7/40\n",
            "1010/1010 [==============================] - 110s 109ms/step - loss: 1.1514 - accuracy: 0.5630\n",
            "Epoch 8/40\n",
            "1010/1010 [==============================] - 110s 109ms/step - loss: 1.0777 - accuracy: 0.5945\n",
            "Epoch 9/40\n",
            "1010/1010 [==============================] - 109s 108ms/step - loss: 0.9965 - accuracy: 0.6286\n",
            "Epoch 10/40\n",
            "1010/1010 [==============================] - 109s 108ms/step - loss: 0.9146 - accuracy: 0.6613\n",
            "Epoch 11/40\n",
            "1010/1010 [==============================] - 109s 108ms/step - loss: 0.8291 - accuracy: 0.6959\n",
            "Epoch 12/40\n",
            "1010/1010 [==============================] - 109s 108ms/step - loss: 0.7441 - accuracy: 0.7282\n",
            "Epoch 13/40\n",
            "1010/1010 [==============================] - 110s 108ms/step - loss: 0.6536 - accuracy: 0.7640\n",
            "Epoch 14/40\n",
            "1010/1010 [==============================] - 110s 108ms/step - loss: 0.5719 - accuracy: 0.7956\n",
            "Epoch 15/40\n",
            "1010/1010 [==============================] - 109s 108ms/step - loss: 0.4929 - accuracy: 0.8240\n",
            "Epoch 16/40\n",
            "1010/1010 [==============================] - 110s 109ms/step - loss: 0.4267 - accuracy: 0.8492\n",
            "Epoch 17/40\n",
            "1010/1010 [==============================] - 110s 109ms/step - loss: 0.3644 - accuracy: 0.8726\n",
            "Epoch 18/40\n",
            "1010/1010 [==============================] - 110s 108ms/step - loss: 0.3015 - accuracy: 0.8962\n",
            "Epoch 19/40\n",
            "1010/1010 [==============================] - 110s 109ms/step - loss: 0.2558 - accuracy: 0.9119\n",
            "Epoch 20/40\n",
            "1010/1010 [==============================] - 110s 109ms/step - loss: 0.2147 - accuracy: 0.9287\n",
            "Epoch 21/40\n",
            "1010/1010 [==============================] - 109s 108ms/step - loss: 0.1871 - accuracy: 0.9384\n",
            "Epoch 22/40\n",
            "1010/1010 [==============================] - 110s 108ms/step - loss: 0.1630 - accuracy: 0.9472\n",
            "Epoch 23/40\n",
            "1010/1010 [==============================] - 110s 108ms/step - loss: 0.1414 - accuracy: 0.9538\n",
            "Epoch 24/40\n",
            "1010/1010 [==============================] - 110s 109ms/step - loss: 0.1175 - accuracy: 0.9624\n",
            "Epoch 25/40\n",
            "1010/1010 [==============================] - 109s 108ms/step - loss: 0.1083 - accuracy: 0.9661\n",
            "Epoch 26/40\n",
            "1010/1010 [==============================] - 109s 108ms/step - loss: 0.1008 - accuracy: 0.9682\n",
            "Epoch 27/40\n",
            "1010/1010 [==============================] - 109s 108ms/step - loss: 0.0787 - accuracy: 0.9758\n",
            "Epoch 28/40\n",
            "1010/1010 [==============================] - 109s 108ms/step - loss: 0.0693 - accuracy: 0.9788\n",
            "Epoch 29/40\n",
            "1010/1010 [==============================] - 109s 108ms/step - loss: 0.0710 - accuracy: 0.9782\n",
            "Epoch 30/40\n",
            "1010/1010 [==============================] - 109s 108ms/step - loss: 0.0721 - accuracy: 0.9762\n",
            "Epoch 31/40\n",
            "1010/1010 [==============================] - 109s 108ms/step - loss: 0.0683 - accuracy: 0.9782\n",
            "Epoch 32/40\n",
            "1010/1010 [==============================] - 110s 109ms/step - loss: 0.0675 - accuracy: 0.9779\n",
            "Epoch 33/40\n",
            "1010/1010 [==============================] - 110s 109ms/step - loss: 0.0571 - accuracy: 0.9811\n",
            "Epoch 34/40\n",
            "1010/1010 [==============================] - 110s 109ms/step - loss: 0.0519 - accuracy: 0.9823\n",
            "Epoch 35/40\n",
            "1010/1010 [==============================] - 110s 109ms/step - loss: 0.0554 - accuracy: 0.9817\n",
            "Epoch 36/40\n",
            "1010/1010 [==============================] - 110s 108ms/step - loss: 0.0477 - accuracy: 0.9839\n",
            "Epoch 37/40\n",
            "1010/1010 [==============================] - 110s 109ms/step - loss: 0.0540 - accuracy: 0.9812\n",
            "Epoch 38/40\n",
            "1010/1010 [==============================] - 110s 109ms/step - loss: 0.0473 - accuracy: 0.9837\n",
            "Epoch 39/40\n",
            "1010/1010 [==============================] - 110s 109ms/step - loss: 0.0380 - accuracy: 0.9873\n",
            "Epoch 40/40\n",
            "1010/1010 [==============================] - 110s 109ms/step - loss: 0.0431 - accuracy: 0.9847\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc2c3010f10>"
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YR8QS7agh5Es",
        "outputId": "9ea9b72d-1f69-4f9a-9cda-bae17afaa865"
      },
      "source": [
        "vggnet.save('/content/gdrive/MyDrive/vggnet_model')"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/gdrive/MyDrive/vggnet_model/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBVqxuvxbKbE",
        "outputId": "449c5137-eee3-48ce-a8c6-081ef568cc42"
      },
      "source": [
        "print(X_test[0].shape)\n",
        "pred = vggnet.predict(X_test)\n",
        "predictions = []\n",
        "for x in pred:\n",
        " predictions.append(np.argmax(x))"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(48, 48, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NUg5aI7buQm",
        "outputId": "923031b6-c8c8-4dcc-a8b7-92047c11a33b"
      },
      "source": [
        "f1_score(y_test, predictions, average='weighted')"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5801448243113637"
            ]
          },
          "metadata": {},
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "JYBWtm3Lc7jv",
        "outputId": "202fd51f-1317-43f1-8a36-8425950bd11a"
      },
      "source": [
        "plt.hist(y_test)"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([522.,  52.,   0., 525.,   0., 867., 613.,   0., 399., 611.]),\n",
              " array([0. , 0.6, 1.2, 1.8, 2.4, 3. , 3.6, 4.2, 4.8, 5.4, 6. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 159
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDAW3onDeHyt",
        "outputId": "ab38f6af-987d-4dcc-97a8-0516451cd4d3"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "matrix = confusion_matrix(y_test, predictions)\n",
        "matrix.diagonal()/matrix.sum(axis=1)"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.47126437, 0.42307692, 0.43047619, 0.78662053, 0.57748777,\n",
              "       0.73433584, 0.42880524])"
            ]
          },
          "metadata": {},
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_DWa_O5cokm"
      },
      "source": [
        "def get_emotion(cl):\n",
        "  k = []\n",
        "  for i in range(len(y_test)):\n",
        "    if y_test.iloc[i] == cl:\n",
        "      k.append(X_test[i])\n",
        "  return np.array(k)\n",
        "\n",
        "angry = get_emotion(0)\n",
        "fear = get_emotion(1)\n",
        "sad = get_emotion(2)\n",
        "neutral = get_emotion(3)\n",
        "happy = get_emotion(4)\n",
        "surprise = get_emotion(5)\n",
        "disgust = get_emotion(6)"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ns0r7vo_inxP"
      },
      "source": [
        "def check(model,input, loss, cl):\n",
        "  pred = []\n",
        "  pred = model.predict(input)\n",
        "  predictions = []\n",
        "  for x in pred:\n",
        "    predictions.append(np.argmax(x))\n",
        "  y_k = []\n",
        "  for i in range(len(input)):\n",
        "    y_k.append(cl)\n",
        "  if loss == f1_score:\n",
        "    return loss(y_k, predictions, average = 'weighted')\n",
        "  else:\n",
        "    return loss(y_k, predictions)"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZKkCYcNmIcK"
      },
      "source": [
        "#эксперименты\n",
        "resnet = tf.keras.applications.resnet50.ResNet50(include_top=True, weights=None, input_shape=(48,48,1), classes=7, pooling='average', classifier_activation='softmax')\n",
        "resnet.compile(loss='categorical_crossentropy', \n",
        "              optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-7), \n",
        "              metrics=['accuracy'])\n",
        "vggnet = tf.keras.applications.vgg19.VGG19(include_top=True, weights=None, input_shape=(48,48,1), classes=7, pooling='average', classifier_activation='softmax')\n",
        "vggnet.compile(loss='categorical_crossentropy', \n",
        "              optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-7), \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulI2_Bw9rgcl",
        "outputId": "a7a9ec82-9a1a-4dcf-9701-135eb892200a"
      },
      "source": [
        "#уменьшу количество угадываемых эмоций\n",
        "all_neutral = data.loc[data['emotion'] == 3]\n",
        "a, at = train_test_split(all_neutral, test_size=0.2, random_state=10)\n",
        "df = data.loc[data['emotion'] != 3]\n",
        "df = df.append(a)\n",
        "df = shuffle(df) \n",
        "print(df)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       emotion                                             pixels       Usage\n",
            "22699        0  62 118 77 25 49 54 78 123 152 152 151 154 158 ...    Training\n",
            "24636        4  9 8 9 13 130 83 0 11 8 15 20 15 12 14 12 12 11...    Training\n",
            "25826        2  82 112 147 142 186 212 194 149 119 99 90 88 86...    Training\n",
            "20937        3  0 0 0 0 0 1 8 18 11 59 177 212 204 189 172 160...    Training\n",
            "20689        0  178 182 201 146 148 159 178 198 198 174 168 59...    Training\n",
            "...        ...                                                ...         ...\n",
            "29835        4  33 42 38 56 70 69 62 66 78 86 101 98 74 74 105...  PublicTest\n",
            "5062         3  22 19 21 22 23 25 26 26 25 26 30 47 82 116 136...    Training\n",
            "11891        4  222 235 238 237 236 231 227 230 212 194 189 19...    Training\n",
            "30665        4  63 89 122 142 136 117 113 120 121 125 128 119 ...  PublicTest\n",
            "16940        5  123 115 104 93 80 104 127 128 124 146 134 138 ...    Training\n",
            "\n",
            "[34089 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUTqq75on4qp"
      },
      "source": [
        "new_y = df['emotion']\n",
        "new_X = np.zeros((len(df), width, height, 1))\n",
        "for i in range(len(df)):\n",
        "    new_X[i] = np.array([int(pixel) for pixel in df['pixels'].iloc[i].split()]).reshape(48,48,1)"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8Soy-lIr3gU"
      },
      "source": [
        "new_X_train, new_X_test, new_y_train, new_y_test = train_test_split(new_X, new_y, test_size=0.1, random_state=10)"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLEKrc_NBUtS"
      },
      "source": [
        "new_X_train = new_X_train / 255"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDlo33_9tRB1"
      },
      "source": [
        "new_y_train = to_categorical(new_y_train)"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMhCWEUxtAcO",
        "outputId": "c738ef36-a76e-4ce0-8d17-6e53442ddec0"
      },
      "source": [
        "resnet.fit(new_X_train, new_y_train, epochs = 2)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "959/959 [==============================] - 114s 111ms/step - loss: 1.8560 - accuracy: 0.3124\n",
            "Epoch 2/2\n",
            "959/959 [==============================] - 107s 111ms/step - loss: 1.5794 - accuracy: 0.4109\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc2d754ed10>"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjEPx6G43nlf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}